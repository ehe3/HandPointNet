{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew Jay Zhou\\AppData\\Roaming\\Python\\Python36\\site-packages\\onnx_tf\\common\\__init__.py:87: UserWarning: FrontendHandler.get_outputs_names is deprecated. It will be removed in future release.. Use node.outputs instead.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('train_eval')\n",
    "sys.path.append('preprocess')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "import math\n",
    "#from utils import group_points_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     162,
     195
    ]
   },
   "outputs": [],
   "source": [
    "nstates_plus_1 = [64,64,128]\n",
    "nstates_plus_2 = [128,128,256]\n",
    "nstates_plus_3 = [256,512,1024,1024,512]\n",
    "\n",
    "class PointNet_Plus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNet_Plus, self).__init__()\n",
    "        self.num_outputs = 26\n",
    "        self.knn_K = 64\n",
    "        self.ball_radius2 = 0.04\n",
    "        self.sample_num_level1 = 512\n",
    "        self.sample_num_level2 = 128\n",
    "        self.INPUT_FEATURE_NUM = 6\n",
    "        \n",
    "        self.netR_1 = nn.Sequential(\n",
    "            # B*INPUT_FEATURE_NUM*sample_num_level1*knn_K\n",
    "            nn.Conv2d(self.INPUT_FEATURE_NUM, nstates_plus_1[0], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_1[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*64*sample_num_level1*knn_K\n",
    "            nn.Conv2d(nstates_plus_1[0], nstates_plus_1[1], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_1[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*64*sample_num_level1*knn_K\n",
    "            nn.Conv2d(nstates_plus_1[1], nstates_plus_1[2], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_1[2]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*128*sample_num_level1*knn_K\n",
    "            nn.MaxPool2d((1,self.knn_K),stride=1)\n",
    "            # B*128*sample_num_level1*1\n",
    "        )\n",
    "        \n",
    "        self.netR_2 = nn.Sequential(\n",
    "            # B*131*sample_num_level2*knn_K\n",
    "            nn.Conv2d(3+nstates_plus_1[2], nstates_plus_2[0], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_2[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*128*sample_num_level2*knn_K\n",
    "            nn.Conv2d(nstates_plus_2[0], nstates_plus_2[1], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_2[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*128*sample_num_level2*knn_K\n",
    "            nn.Conv2d(nstates_plus_2[1], nstates_plus_2[2], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_2[2]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*256*sample_num_level2*knn_K\n",
    "            nn.MaxPool2d((1,self.knn_K),stride=1)\n",
    "            # B*256*sample_num_level2*1\n",
    "        )\n",
    "        \n",
    "        self.netR_3 = nn.Sequential(\n",
    "            # B*259*sample_num_level2*1\n",
    "            nn.Conv2d(3+nstates_plus_2[2], nstates_plus_3[0], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_3[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*256*sample_num_level2*1\n",
    "            nn.Conv2d(nstates_plus_3[0], nstates_plus_3[1], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_3[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*512*sample_num_level2*1\n",
    "            nn.Conv2d(nstates_plus_3[1], nstates_plus_3[2], kernel_size=(1, 1)),\n",
    "            nn.BatchNorm2d(nstates_plus_3[2]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*1024*sample_num_level2*1\n",
    "            nn.MaxPool2d((self.sample_num_level2,1),stride=1),\n",
    "            # B*1024*1*1\n",
    "        )\n",
    "        \n",
    "        self.netR_FC = nn.Sequential(\n",
    "            # B*1024\n",
    "            nn.Linear(nstates_plus_3[2], nstates_plus_3[3]),\n",
    "            nn.BatchNorm1d(nstates_plus_3[3]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*1024\n",
    "            nn.Linear(nstates_plus_3[3], nstates_plus_3[4]),\n",
    "            nn.BatchNorm1d(nstates_plus_3[4]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # B*512\n",
    "            nn.Linear(nstates_plus_3[4], self.num_outputs),\n",
    "            # B*num_outputs\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # x: B*INPUT_FEATURE_NUM*sample_num_level1*knn_K, y: B*3*sample_num_level1*1\n",
    "        x = self.netR_1(x)\n",
    "        # B*128*sample_num_level1*1\n",
    "        x = torch.cat((y, x),1).squeeze(-1)\n",
    "        # B*(3+128)*sample_num_level1\n",
    "        \n",
    "        #inputs_level2, inputs_level2_center = group_points_2(x, self.sample_num_level1, self.sample_num_level2, self.knn_K, self.ball_radius2)\n",
    "        inputs_level2, inputs_level2_center = group_points_2(x, 512, 128, 64, 0.04)\n",
    "        # B*131*sample_num_level2*knn_K, B*3*sample_num_level2*1\n",
    "        \n",
    "        # B*131*sample_num_level2*knn_K\n",
    "        x = self.netR_2(inputs_level2)\n",
    "        # B*256*sample_num_level2*1\n",
    "        x = torch.cat((inputs_level2_center, x),1)\n",
    "        # B*259*sample_num_level2*1\n",
    "        \n",
    "        x = self.netR_3(x)\n",
    "        # B*1024*1*1\n",
    "        x = x.view(-1,nstates_plus_3[2])\n",
    "        # B*1024\n",
    "        x = self.netR_FC(x)\n",
    "        # B*num_outputs\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "def group_points_2(points, sample_num_level1, sample_num_level2, knn_K, ball_radius):\n",
    "    torch.set_printoptions(threshold=10000)\n",
    "    # group points using knn and ball query\n",
    "    # points: B*(3+128)*512\n",
    "    cur_train_size = points.size(0)\n",
    "    inputs1_diff = points[:,0:3,:].unsqueeze(1).expand(cur_train_size,sample_num_level2,3,sample_num_level1) \\\n",
    "                 - points[:,0:3,0:sample_num_level2].transpose(1,2).unsqueeze(-1).expand(cur_train_size,sample_num_level2,3,sample_num_level1)# B * 128 * 3 * 512\n",
    "    inputs1_diff = torch.mul(inputs1_diff, inputs1_diff)    # B * 128 * 3 * 512\n",
    "    inputs1_diff = inputs1_diff.sum(2)                      # B * 128 * 512\n",
    "    dists, inputs1_idx = torch.topk(inputs1_diff, knn_K, 2, largest=False, sorted=False)  # dists: B * 128 * 64; inputs1_idx: B * 128 * 64\n",
    "\n",
    "    # ball query\n",
    "#     invalid_map = dists.gt(ball_radius) # B * 128 * 64, invalid_map.float().sum()   \n",
    "#     for jj in range(sample_num_level2):\n",
    "#         inputs1_idx.data[:,jj,:][invalid_map.data[:,jj,:]] =jj\n",
    "    new_inputs1_idx = ball_query(dists, inputs1_idx) \n",
    "\n",
    "\n",
    "    idx_group_l1_long = new_inputs1_idx.view(cur_train_size,1,sample_num_level2*knn_K).expand(cur_train_size,points.size(1),sample_num_level2*knn_K)\n",
    "    inputs_level2 = points.gather(2,idx_group_l1_long).view(cur_train_size,points.size(1),sample_num_level2,knn_K) # B*131*128*64\n",
    "\n",
    "    inputs_level2_center = points[:,0:3,0:sample_num_level2].unsqueeze(3)       # B*3*128*1\n",
    "    tmp = inputs_level2[:,0:3,:,:] - inputs_level2_center.expand(cur_train_size,3,sample_num_level2,knn_K) # B*3*128*64\n",
    "    inputs_level2 = torch.cat((tmp, inputs_level2[:, 3:, :, :]), dim=1)\n",
    "    \n",
    "    \n",
    "    return inputs_level2, inputs_level2_center\n",
    "    # inputs_level2: B*131*sample_num_level2*knn_K, inputs_level2_center: B*3*sample_num_level2*1\n",
    "\n",
    "@torch.jit.script\n",
    "def ball_query(dists, inputs1_idx):\n",
    "    idx = inputs1_idx.clone()\n",
    "    invalid_map = dists.gt(0.04) # B * 128 * 64, invalid_map.float().sum()\n",
    "    #ball radius 2 = 0.04\n",
    "    \n",
    "    # consider optimizing \n",
    "    for jj in range(128): #sample_num_level2 = 128\n",
    "        for k in range(64):\n",
    "            i = invalid_map[:,jj,k]\n",
    "            if bool(i == 1):\n",
    "                idx[:, jj, k] = jj\n",
    "            \n",
    "        \n",
    "    return idx\n",
    "    \n",
    "def group_points(points):\n",
    "    sample_num_level1 = 512\n",
    "    sample_num_level2 = 128\n",
    "    ball_radius       = 0.015\n",
    "    ball_radius2      = 0.04\n",
    "    SAMPLE_NUM        = 1024\n",
    "    knn_K             = 64\n",
    "    INPUT_FEATURE_NUM = 6\n",
    "    # group points using knn and ball query\n",
    "    # points: B * 1024 * 6\n",
    "   \n",
    "    cur_train_size = len(points)\n",
    "    inputs1_diff = points[:,:,0:3].transpose(1,2).unsqueeze(1).expand(cur_train_size,sample_num_level1,3, SAMPLE_NUM) \\\n",
    "                 - points[:,0:sample_num_level1,0:3].unsqueeze(-1).expand(cur_train_size,sample_num_level1,3,SAMPLE_NUM)# B * 512 * 3 * 1024\n",
    "    inputs1_diff = torch.mul(inputs1_diff, inputs1_diff)    # B * 512 * 3 * 1024\n",
    "    inputs1_diff = inputs1_diff.sum(2)                      # B * 512 * 1024\n",
    "    dists, inputs1_idx = torch.topk(inputs1_diff, knn_K, 2, largest=False, sorted=False)  # dists: B * 512 * 64; inputs1_idx: B * 512 * 64\n",
    "        \n",
    "    # ball query\n",
    "    invalid_map = dists.gt(ball_radius) # B * 512 * 64\n",
    "    for jj in range(sample_num_level1):\n",
    "        inputs1_idx[:,jj,:][invalid_map[:,jj,:]] = jj\n",
    "        \n",
    "    idx_group_l1_long = inputs1_idx.view(cur_train_size,sample_num_level1*knn_K,1).expand(cur_train_size,sample_num_level1*knn_K,INPUT_FEATURE_NUM)\n",
    "    inputs_level1 = points.gather(1,idx_group_l1_long).view(cur_train_size,sample_num_level1,knn_K,INPUT_FEATURE_NUM) # B*512*64*6\n",
    "\n",
    "    inputs_level1_center = points[:,0:sample_num_level1,0:3].unsqueeze(2)       # B*512*1*3\n",
    "    inputs_level1[:,:,:,0:3] = inputs_level1[:,:,:,0:3] - inputs_level1_center.expand(cur_train_size,sample_num_level1,knn_K,3)\n",
    "    inputs_level1 = inputs_level1.unsqueeze(1).transpose(1,4).squeeze(4)  # B*6*512*64\n",
    "    inputs_level1_center = inputs_level1_center.contiguous().view(-1,1,sample_num_level1,3).transpose(1,3)  # B*3*512*1\n",
    "    return inputs_level1, inputs_level1_center\n",
    "    #inputs_level1: B*INPUT_FEATURE_NUM*sample_num_level1*knn_K, inputs_level1_center: B*3*sample_num_level1*1\n",
    "    \n",
    "def load_net(weights_file='train_eval/results/iter_003/netR_40.pth', ngpu_trained=4, map_location='cpu'):\n",
    "    if ngpu_trained > 0:\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    netR = PointNet_Plus()\n",
    "    \n",
    "    if ngpu_trained > 1:\n",
    "        netR.netR_1 = nn.DataParallel(netR.netR_1, range(ngpu_trained))\n",
    "        netR.netR_2 = nn.DataParallel(netR.netR_2, range(ngpu_trained))\n",
    "        netR.netR_3 = nn.DataParallel(netR.netR_3, range(ngpu_trained))\n",
    "\n",
    "    netR.load_state_dict(torch.load('train_eval/results/iter_003/netR_40.pth', map_location='cpu'))\n",
    "    return netR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "net = load_net()\n",
    "net.eval()\n",
    "\n",
    "dummy_inputs_level1, dummy_input_level1_center = group_points(torch.randn(1, 1024, 6))\n",
    "\n",
    "dummy_input = (dummy_inputs_level1, dummy_input_level1_center)\n",
    "traced_script_module = torch.jit.trace(net, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
